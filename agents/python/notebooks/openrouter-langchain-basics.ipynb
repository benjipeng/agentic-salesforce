{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain + OpenRouter + Salesforce\n",
    "\n",
    "This notebook:\n",
    "- Loads secrets from `agents/python/.env.local`.\n",
    "- Sets up an OpenRouter-backed LangChain `ChatOpenAI` client.\n",
    "- Uses JWT to read Accounts from the RenoCrypt scratch org via REST/SOQL.\n",
    "- Asks the LLM for an overview of the customer base from that snapshot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1934d0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Loaded OpenRouter API key (not shown)\n",
      "Python root: /Users/ac/dev/salesforce/ACDevHub/agents/python\n",
      "Project root: /Users/ac/dev/salesforce/ACDevHub\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def find_python_root(max_up: int = 10) -> Path:\n",
    "    \"\"\"Locate the `agents/python` directory starting from the current working dir.\"\"\"\n",
    "    p = Path.cwd().resolve()\n",
    "    for _ in range(max_up):\n",
    "        if p.name == \"python\" and p.parent.name == \"agents\":\n",
    "            return p\n",
    "        candidate = p / \"agents\" / \"python\"\n",
    "        if candidate.exists():\n",
    "            return candidate\n",
    "        p = p.parent\n",
    "    raise RuntimeError(\"Could not locate agents/python directory from current path\")\n",
    "\n",
    "PYTHON_ROOT = find_python_root()\n",
    "PROJECT_ROOT = PYTHON_ROOT.parent.parent\n",
    "\n",
    "# Load .env then .env.local (local overrides)\n",
    "env_main = PYTHON_ROOT / \".env\"\n",
    "env_local = PYTHON_ROOT / \".env.local\"\n",
    "\n",
    "if env_main.exists():\n",
    "    load_dotenv(env_main, override=False)\n",
    "if env_local.exists():\n",
    "    load_dotenv(env_local, override=True)\n",
    "\n",
    "# Support either OPENROUTER_API_KEY or OPEN_ROUTER_API\n",
    "raw_key = os.getenv(\"OPENROUTER_API_KEY\") or os.getenv(\"OPEN_ROUTER_API\")\n",
    "if not raw_key:\n",
    "    raise RuntimeError(\"Missing OPENROUTER_API_KEY or OPEN_ROUTER_API in agents/python/.env.local\")\n",
    "\n",
    "os.environ[\"OPENROUTER_API_KEY\"] = raw_key\n",
    "\n",
    "print(\"âœ“ Loaded OpenRouter API key (not shown)\")\n",
    "print(f\"Python root: {PYTHON_ROOT}\")\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "976afd3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(profile={}, client=<openai.resources.chat.completions.completions.Completions object at 0x112c74490>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x113667510>, root_client=<openai.OpenAI object at 0x11276fb90>, root_async_client=<openai.AsyncOpenAI object at 0x113667210>, model_name='tngtech/deepseek-r1t2-chimera:free', model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://openrouter.ai/api/v1')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# OpenRouter-backed LLM (update model as desired)\n",
    "llm = ChatOpenAI(\n",
    "    model=\"tngtech/deepseek-r1t2-chimera:free\",\n",
    "    api_key=os.environ[\"OPENROUTER_API_KEY\"],\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    ")\n",
    "\n",
    "llm\n",
    "# Optional sanity check (commented to avoid automatic token use):\n",
    "# llm.invoke(\"Say a short hello from OpenRouter.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4b442f",
   "metadata": {},
   "source": [
    "## Salesforce JWT auth + REST helpers\n",
    "\n",
    "Reuse the same JWT flow as the other notebooks to read from the scratch org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e48ac6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Salesforce JWT auth ok\n",
      "Instance URL: https://force-enterprise-762-dev-ed.scratch.my.salesforce.com\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import urllib.parse\n",
    "\n",
    "import httpx\n",
    "import jwt\n",
    "\n",
    "required_sf_keys = [\n",
    "    \"SF_CLIENT_ID\",\n",
    "    \"SF_USERNAME\",\n",
    "    \"SF_LOGIN_URL\",\n",
    "    \"SF_AUDIENCE\",\n",
    "    \"SF_JWT_KEY_PATH\",\n",
    "]\n",
    "missing_sf = [k for k in required_sf_keys if not os.environ.get(k)]\n",
    "if missing_sf:\n",
    "    raise RuntimeError(f\"Missing required SF env vars: {', '.join(missing_sf)}\")\n",
    "\n",
    "SF_CLIENT_ID = os.environ[\"SF_CLIENT_ID\"]\n",
    "SF_USERNAME = os.environ[\"SF_USERNAME\"]\n",
    "SF_LOGIN_URL = os.environ[\"SF_LOGIN_URL\"].rstrip(\"/\")\n",
    "SF_AUDIENCE = os.environ[\"SF_AUDIENCE\"]\n",
    "SF_JWT_KEY_PATH = os.environ[\"SF_JWT_KEY_PATH\"]\n",
    "SF_API_VERSION = os.environ.get(\"SF_API_VERSION\", \"65.0\")\n",
    "\n",
    "\n",
    "def build_sf_jwt_assertion() -> str:\n",
    "    key_bytes = Path(SF_JWT_KEY_PATH).read_bytes()\n",
    "    now = int(time.time())\n",
    "    payload = {\n",
    "        \"iss\": SF_CLIENT_ID,\n",
    "        \"sub\": SF_USERNAME,\n",
    "        \"aud\": SF_AUDIENCE,\n",
    "        \"exp\": now + 5 * 60,\n",
    "    }\n",
    "    token = jwt.encode(payload, key_bytes, algorithm=\"RS256\")\n",
    "    if isinstance(token, bytes):\n",
    "        token = token.decode(\"utf-8\")\n",
    "    return token\n",
    "\n",
    "\n",
    "def request_sf_access_token() -> tuple[str, str]:\n",
    "    assertion = build_sf_jwt_assertion()\n",
    "    url = f\"{SF_LOGIN_URL}/services/oauth2/token\"\n",
    "    data = {\n",
    "        \"grant_type\": \"urn:ietf:params:oauth:grant-type:jwt-bearer\",\n",
    "        \"assertion\": assertion,\n",
    "    }\n",
    "    with httpx.Client(timeout=20) as client:\n",
    "        resp = client.post(url, data=data)\n",
    "        resp.raise_for_status()\n",
    "    body = resp.json()\n",
    "    token = body[\"access_token\"]\n",
    "    instance_url = body[\"instance_url\"]\n",
    "    os.environ[\"SF_ACCESS_TOKEN\"] = token\n",
    "    os.environ[\"SF_INSTANCE_URL\"] = instance_url\n",
    "    return token, instance_url\n",
    "\n",
    "\n",
    "SF_ACCESS_TOKEN, SF_INSTANCE_URL = request_sf_access_token()\n",
    "print(\"âœ“ Salesforce JWT auth ok\")\n",
    "print(f\"Instance URL: {SF_INSTANCE_URL}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2eb9691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ sf_request and soql_query ready\n"
     ]
    }
   ],
   "source": [
    "def sf_request(path: str, method: str = \"GET\", **kwargs):\n",
    "    \"\"\"Minimal helper for REST calls into the scratch org.\"\"\"\n",
    "    base = SF_INSTANCE_URL.rstrip(\"/\")\n",
    "    if path.startswith(\"http://\") or path.startswith(\"https://\"):\n",
    "        url = path\n",
    "    else:\n",
    "        if not path.startswith(\"/\"):\n",
    "            path = \"/\" + path\n",
    "        url = base + path\n",
    "\n",
    "    headers = kwargs.pop(\"headers\", {})\n",
    "    headers.setdefault(\"Authorization\", f\"Bearer {SF_ACCESS_TOKEN}\")\n",
    "    headers.setdefault(\"Content-Type\", \"application/json\")\n",
    "\n",
    "    with httpx.Client(timeout=30) as client:\n",
    "        resp = client.request(method, url, headers=headers, **kwargs)\n",
    "        resp.raise_for_status()\n",
    "        if not resp.text:\n",
    "            return None\n",
    "        try:\n",
    "            return resp.json()\n",
    "        except json.JSONDecodeError:\n",
    "            return resp.text\n",
    "\n",
    "\n",
    "def soql_query(soql: str) -> list[dict]:\n",
    "    encoded = urllib.parse.quote(soql)\n",
    "    first = sf_request(f\"/services/data/v{SF_API_VERSION}/query?q={encoded}\")\n",
    "    records = list(first.get(\"records\", []))\n",
    "    next_url = first.get(\"nextRecordsUrl\")\n",
    "    while next_url:\n",
    "        page = sf_request(next_url)\n",
    "        records.extend(page.get(\"records\", []))\n",
    "        next_url = page.get(\"nextRecordsUrl\")\n",
    "    return records\n",
    "\n",
    "print(\"âœ“ sf_request and soql_query ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7569eaa6",
   "metadata": {},
   "source": [
    "## Ask the LLM for an overview\n",
    "\n",
    "This cell pulls a small snapshot of Accounts and asks the model for a concise summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a01466a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- 4/8 (50%) active accounts are Enterprise, 2/8 Mid-Market, 1/8 SMB (excluding sample account with null segmentation)  \n",
      "- Revenue tiers show strong performers: Northern Lights Bank ($420k ARR) and Acme Health ($300k ARR). 2 accounts (Everest Insurance, CloudNova) show $0 ARR/MRR  \n",
      "- HealthScore: 3 accounts (Acme Health 85, Northern Lights 78, UrbanGrid 82) >75 = healthy. 3 accounts (Vertex Mfg 58, BlueSky 65, Greenfield 72) <75 = risk candidates  \n",
      "- Support Tier alignment: Gold-tier accounts (Acme, Northern Lights, UrbanGrid) drive 64% of total ARR. Anomaly: Vertex Mfg (Enterprise, $240k ARR) has Bronze support despite revenue  \n",
      "- Data gaps: Everest Insurance/CloudNova show $0 ARR/MRR+0 HealthScore (likely unonboarded). All accounts lack ChurnRisk data. Sample account has null values across all metrics\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Fetch a snapshot of RenoCrypt accounts\n",
    "accounts = soql_query(\n",
    "    \"SELECT Id, Name, Website, Industry, ARR__c, MRR__c, HealthScore__c, Segment__c, Support_Tier__c \"\n",
    "    \"FROM Account ORDER BY CreatedDate DESC LIMIT 20\"\n",
    ")\n",
    "\n",
    "# Trim to the most relevant fields before sending to the model\n",
    "accounts_brief = [\n",
    "    {\n",
    "        \"Id\": a[\"Id\"],\n",
    "        \"Name\": a.get(\"Name\"),\n",
    "        \"Website\": a.get(\"Website\"),\n",
    "        \"Industry\": a.get(\"Industry\"),\n",
    "        \"ARR__c\": a.get(\"ARR__c\"),\n",
    "        \"MRR__c\": a.get(\"MRR__c\"),\n",
    "        \"HealthScore__c\": a.get(\"HealthScore__c\"),\n",
    "        \"ChurnRisk__c\": a.get(\"ChurnRisk__c\"),\n",
    "        \"Segment__c\": a.get(\"Segment__c\"),\n",
    "        \"Support_Tier__c\": a.get(\"Support_Tier__c\"),\n",
    "    }\n",
    "    for a in accounts\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You analyze SaaS customer data. Output only the requested format with no preamble, introduction, or conclusion.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Analyze this Salesforce account data:\\n\\n\"\n",
    "            \"<accounts_data>\\n{accounts_json}\\n</accounts_data>\\n\\n\"\n",
    "            \"Output exactly 5-10 bullet points covering:\\n\"\n",
    "            \"- Customer segmentation (Enterprise/Mid-Market/SMB distribution)\\n\"\n",
    "            \"- Revenue tiers (ARR/MRR patterns)\\n\"\n",
    "            \"- Health score analysis (strong vs at-risk accounts)\\n\"\n",
    "            \"- Support tier alignment with revenue\\n\"\n",
    "            \"- Missing data or anomalies\\n\\n\"\n",
    "            \"Output ONLY the bullet points. No text before or after.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "overview = chain.invoke({\"accounts_json\": json.dumps(accounts_brief, default=str)})\n",
    "print(overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "okng89aac7p",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 30 tasks (18 open, 10 overdue)\n",
      "Analyzing with LLM...\n",
      "\n",
      "\n",
      "- **Task subjects/themes**: Dominant themes include technical implementation (API settings, alert routing), migration/rollout planning, audit/compliance (findings, evidence), business operations (renewals, pricing proposals), and clustered \"Quarterly business review\" tasks (7x in December 2025).  \n",
      "- **Status breakdown**: 60% open (18/30 tasks), including 10 overdue items; 40% closed (12/30 tasks all marked \"Completed\").  \n",
      "- **Overdue task analysis**: 10 overdue tasks (33% of total), including 7 High-priority items (e.g., \"Send updated pricing proposal,\" \"Document current incident process\") and 3 Normal-priority (e.g., \"Align on SecOps coverage\").  \n",
      "- **Priority distribution**: High-priority dominates (15 tasks, 50%), followed by Normal (14 tasks, 47%), and a single Low-priority task (\"Recommend alert defaults\").  \n",
      "- **Critical bottlenecks**: 7/10 overdue tasks are High-priority (e.g., \"Investigate metrics latency,\" \"Confirm SLO targets\"), risking operational delays and compliance gaps.  \n",
      "- **Recurring task risk**: 7 identical \"Quarterly business review\" tasks scheduled mid-December 2025 (all Normal priority, Not Started), creating deadline congestion and potential oversight.  \n",
      "- **Compliance focus**: Audit-related tasks show mixed progress (\"Present audit findings\" completed vs. \"Prepare audit evidence\" overdue).  \n",
      "- **Workshop/planning cadence**: Scheduled workshops (onboarding, GenAI) and planning tasks (rollout, SRE) are largely complete except \"Schedule GenAI workshop\" (Not Started).  \n",
      "- **Technical maintenance**: Several High-priority optimization tasks completed (e.g., \"Tune synthetic checks,\" \"Review API rate limit settings\"), indicating proactive system management.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8c513f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 30 tasks (18 open, 10 overdue)\n",
      "Analyzing with LLM...\n",
      "\n",
      "\n",
      "\n",
      "- **Task subjects/themes**: Planning/Collaboration (onboarding, rollout planning, workshops), Technical/Operations (API settings, alert routing, metrics tuning), Review/Audit (contract sign-off, audit findings, SLO targets), Routine Business Reviews (multiple quarterly reviews)  \n",
      "- **Status breakdown**: 12 completed tasks (40%), 18 open tasks (60% - including 6 \"In Progress\", 12 \"Not Started\")  \n",
      "- **Overdue tasks**: 10 total overdue (56% of open tasks) - Key subjects: Pricing proposal, SecOps coverage, legacy server guidance, metrics latency investigation, SLO confirmation, incident process documentation  \n",
      "- **Overdue priority mix**: 7 High (e.g., \"Review renewal scope\", \"Investigate metrics latency\"), 3 Normal (e.g., \"Align on SecOps coverage\", \"Gather DevOps requirements\")  \n",
      "- **Priority distribution**: High (20 tasks, 67%), Normal (9 tasks, 30%), Low (1 task, 3%)  \n",
      "- **Risk areas**: 8 overdue High-priority technical/operational items, clustered overdue deadlines in Jun-Jul 2025 (5 overdue tasks)  \n",
      "- **Notable pattern**: High concentration of \"Quarterly business review\" tasks (7) scheduled Dec 2025 - potential duplication/coordination risk  \n",
      "- **Thematic trend**: Focus shifts from implementation (2024) to monitoring/optimization (2025) and strategic reviews (late 2025-2026)  \n",
      "- **Execution risk**: Multiple critical path items overdue (\"Send updated pricing proposal\", \"Define pilot success metrics\") potentially impacting commercial timelines  \n",
      "- **Process note**: Only 1 Low-priority task completed; routine work heavily skewed toward High-priority classification\n"
     ]
    }
   ],
   "source": [
    "# BY CLAUDE 4.5 Sonnet\n",
    "from datetime import datetime, date\n",
    "\n",
    "# Fetch Tasks from Salesforce (removed Type field which may not exist)\n",
    "tasks = soql_query(\n",
    "    \"SELECT Id, Subject, Status, ActivityDate, IsClosed, Priority \"\n",
    "    \"FROM Task \"\n",
    "    \"ORDER BY ActivityDate ASC NULLS LAST LIMIT 100\"\n",
    ")\n",
    "\n",
    "# Calculate today's date for overdue check\n",
    "today = date.today()\n",
    "\n",
    "# Enrich tasks with overdue status\n",
    "tasks_enriched = []\n",
    "for task in tasks:\n",
    "    task_data = {\n",
    "        \"Id\": task[\"Id\"],\n",
    "        \"Subject\": task.get(\"Subject\"),\n",
    "        \"Status\": task.get(\"Status\"),\n",
    "        \"ActivityDate\": task.get(\"ActivityDate\"),\n",
    "        \"IsClosed\": task.get(\"IsClosed\"),\n",
    "        \"Priority\": task.get(\"Priority\"),\n",
    "    }\n",
    "    \n",
    "    # Calculate if overdue\n",
    "    if task.get(\"ActivityDate\") and not task.get(\"IsClosed\"):\n",
    "        activity_date = datetime.strptime(task[\"ActivityDate\"], \"%Y-%m-%d\").date()\n",
    "        task_data[\"IsOverdue\"] = activity_date < today\n",
    "    else:\n",
    "        task_data[\"IsOverdue\"] = False\n",
    "    \n",
    "    tasks_enriched.append(task_data)\n",
    "\n",
    "# Count overdue tasks\n",
    "overdue_count = sum(1 for t in tasks_enriched if t[\"IsOverdue\"])\n",
    "total_open = sum(1 for t in tasks_enriched if not t[\"IsClosed\"])\n",
    "\n",
    "print(f\"Loaded {len(tasks_enriched)} tasks ({total_open} open, {overdue_count} overdue)\")\n",
    "print(f\"Analyzing with LLM...\\n\")\n",
    "\n",
    "# Prompt for task analysis\n",
    "task_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You analyze CRM task data. Output only the requested format with no preamble, introduction, or conclusion.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Analyze this Salesforce task data:\\n\\n\"\n",
    "            \"<task_data>\\n{tasks_json}\\n</task_data>\\n\\n\"\n",
    "            \"Summary context:\\n\"\n",
    "            \"- Total tasks: {total_tasks}\\n\"\n",
    "            \"- Open tasks: {open_tasks}\\n\"\n",
    "            \"- Overdue tasks: {overdue_tasks}\\n\\n\"\n",
    "            \"Output exactly 6-10 bullet points covering:\\n\"\n",
    "            \"- Task subjects/themes (categorize by content)\\n\"\n",
    "            \"- Status breakdown (open vs closed)\\n\"\n",
    "            \"- Overdue task analysis (count, subjects, priorities)\\n\"\n",
    "            \"- Priority distribution\\n\"\n",
    "            \"- Notable patterns or risks\\n\\n\"\n",
    "            \"Output ONLY the bullet points. No text before or after.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "task_chain = task_prompt | llm | StrOutputParser()\n",
    "\n",
    "task_analysis = task_chain.invoke({\n",
    "    \"tasks_json\": json.dumps(tasks_enriched[:50], default=str),  # Limit to 50 for token efficiency\n",
    "    \"total_tasks\": len(tasks_enriched),\n",
    "    \"open_tasks\": total_open,\n",
    "    \"overdue_tasks\": overdue_count,\n",
    "})\n",
    "\n",
    "print(task_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task_analysis_cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 30 tasks (18 open, 10 overdue)\n",
      "Analyzing with LLM...\n",
      "\n",
      "\n",
      "\n",
      "```markdown\n",
      "### Salesforce Task Analysis - Executive Summary\n",
      "\n",
      "1. **Task Subjects/Themes**  \n",
      "   - **Audits & Compliance**: Present audit findings, Prepare audit evidence, Review API rate limit settings  \n",
      "   - **Renewals & Contracts**: Finalize contract signatures, Review renewal scope, Send updated pricing proposal  \n",
      "   - **Technical Operations**: Analyze dashboard queries, Test alert routing, Tune synthetic checks, Investigate metrics latency  \n",
      "   - **Workshops & Planning**: Schedule onboarding workshop, Plan phased rollout, Schedule GenAI workshop  \n",
      "   - **SRE/DevOps Initiatives**: Define SRE engagement scope, Define pilot success metrics, Gather DevOps requirements  \n",
      "   - **Incident Management**: Document current incident process, Review pilot KPIs  \n",
      "   - **Business Reviews**: Quarterly business reviews (6x, multiple stakeholders)  \n",
      "\n",
      "2. **Status Breakdown**  \n",
      "   - **Completed**: 16 tasks  \n",
      "   - **Open**:  \n",
      "     - *In Progress*: 6 tasks  \n",
      "     - *Not Started*: 8 tasks  \n",
      "\n",
      "3. **Overdue Task Analysis**  \n",
      "   - **Total Overdue**: 9 tasks (DueDate < 2025-11-27)  \n",
      "   - **Critical Overdue (High Priority)**:  \n",
      "     - `Send updated pricing proposal` (Due 2025-06-25, Not Started)  \n",
      "     - `Provide legacy server guidance` (Due 2025-01-28, In Progress)  \n",
      "     - `Investigate metrics latency` (Due 2025-07-21, In Progress)  \n",
      "     - `Document current incident process` (Due 2025-11-05, In Progress)  \n",
      "\n",
      "4. **Priority Distribution**  \n",
      "   - **High**: 16 tasks  \n",
      "   - **Normal**: 12 tasks  \n",
      "   - **Low**: 1 task  \n",
      "\n",
      "5. **Critical Bottlenecks**  \n",
      "   - **High-priority tasks stalled**:  \n",
      "     - `Send updated pricing proposal` (Not Started, critical for renewal)  \n",
      "     - `Investigate metrics latency` (In Progress, operational risk)  \n",
      "     - `Prepare rollout business case` (Not Started, impacts Q4 rollout)  \n",
      "   - **Execution delays**:  \n",
      "     - Legacy server guidance (7 months overdue)  \n",
      "     - Renewal scope/pricing alignment (>5 months overdue)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Gemini 3.0 Pro\n",
    "from datetime import datetime\n",
    "\n",
    "# 1. Define Current Date (simulated per user context)\n",
    "current_date = \"2025-11-27\"\n",
    "\n",
    "# 2. Fetch Task Data\n",
    "# We want specific fields to allow the LLM to determine overdue status and themes\n",
    "tasks = soql_query(\n",
    "    \"SELECT Id, Subject, Status, Priority, ActivityDate, Description, Who.Name, What.Name \"\n",
    "    \"FROM Task \"\n",
    "    \"ORDER BY ActivityDate ASC \"\n",
    "    \"LIMIT 50\"\n",
    ")\n",
    "\n",
    "# 3. Pre-calc overdue count for quick validation\n",
    "total_tasks = len(tasks)\n",
    "open_tasks = [t for t in tasks if t['Status'] != 'Completed']\n",
    "overdue_tasks = [\n",
    "    t for t in open_tasks \n",
    "    if t['ActivityDate'] and t['ActivityDate'] < current_date\n",
    "]\n",
    "\n",
    "print(f\"Loaded {total_tasks} tasks ({len(open_tasks)} open, {len(overdue_tasks)} overdue)\")\n",
    "print(\"Analyzing with LLM...\\n\")\n",
    "\n",
    "# 4. Prepare Data for LLM\n",
    "# Minimize token usage by sending only necessary fields\n",
    "tasks_context = [\n",
    "    {\n",
    "        \"Subject\": t.get(\"Subject\"),\n",
    "        \"Status\": t.get(\"Status\"),\n",
    "        \"Priority\": t.get(\"Priority\"),\n",
    "        \"DueDate\": t.get(\"ActivityDate\"),\n",
    "        \"Description\": t.get(\"Description\")\n",
    "    }\n",
    "    for t in tasks\n",
    "]\n",
    "\n",
    "# 5. Construct Prompt\n",
    "prompt_task_analysis = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a Senior Sales Operations Analyst. Your job is to identify risks and bottlenecks in workflow.\"\n",
    "    ),\n",
    "    (\n",
    "        \"human\",\n",
    "        \"Current Date: {current_date}\\n\\n\"\n",
    "        \"Analyze the following Salesforce Task data:\\n\"\n",
    "        \"<tasks>\\n{tasks_json}\\n</tasks>\\n\\n\"\n",
    "        \"Provide a professional executive summary (bullet points) assessing:\\n\"\n",
    "        \"1. **Task subjects/themes**: Group tasks into high-level categories (e.g., Audit, Sales, Technical).\\n\"\n",
    "        \"2. **Status breakdown**: Brief count of Open vs Completed.\\n\"\n",
    "        \"3. **Overdue task analysis**: specific count of overdue items (DueDate < Current Date). Highlight the most critical overdue items (High Priority).\\n\"\n",
    "        \"4. **Priority distribution**: Breakdown of urgency.\\n\"\n",
    "        \"5. **Critical bottlenecks**: Identify specific high-priority tasks that are stalled.\\n\\n\"\n",
    "        \"Format the output as concise Markdown bullet points.\"\n",
    "    )\n",
    "])\n",
    "\n",
    "# 6. Chain and Invoke\n",
    "chain_tasks = prompt_task_analysis | llm | StrOutputParser()\n",
    "\n",
    "analysis = chain_tasks.invoke({\n",
    "    \"current_date\": current_date,\n",
    "    \"tasks_json\": json.dumps(tasks_context, default=str)\n",
    "})\n",
    "\n",
    "print(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd38472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- **Operational Themes**: 7 clustered \"Quarterly business review\" tasks (Dec 2025) and technical focuses like SRE/SecOps workshops, system migration, and audit prep  \n",
      "- **Status Imbalance**: 60% open tasks (18/30), including 10 overdue; 40% completed (12/30)  \n",
      "- **Critical Overdues**: 6 High-priority tasks overdue (e.g., \"Send updated pricing proposal\", \"Investigate metrics latency\", \"Prepare audit evidence\") plus 4 Normal-priority (e.g., \"Align on SecOps coverage\")  \n",
      "- **Priority Skew**: High-priority dominates (43% of all tasks), with 6/10 overdue items being High-priority  \n",
      "- **Cluster Risk**: 7 \"Quarterly business review\" tasks (+1 GenAI workshop) concentrated in Dec 2025â€“Jan 2026, risking deadline collisions  \n",
      "- **Immediate Risks**: 3 overdue High-priority planning tasks (\"Define pilot success metrics\", \"Confirm SLO targets\", \"Document incident process\") potentially blocking Q4 initiatives  \n",
      "- **Next Steps**: Urgently address overdue High-priority items; preemptively schedule Dec 2025 review tasks to avoid recurrence of overdue cluster\n"
     ]
    }
   ],
   "source": [
    "# ChatGPT 5.1 Code Max\n",
    "import json\n",
    "from datetime import date\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Fresh task snapshot (independent of the cell above)\n",
    "task_rows = soql_query(\n",
    "    \"SELECT Id, Subject, Status, ActivityDate, IsClosed, Priority \"\n",
    "    \"FROM Task ORDER BY ActivityDate ASC NULLS LAST LIMIT 80\"\n",
    ")\n",
    "\n",
    "today = date.today()\n",
    "open_cnt = 0\n",
    "overdue_cnt = 0\n",
    "tasks_payload = []\n",
    "\n",
    "for t in task_rows:\n",
    "    is_closed = bool(t.get(\"IsClosed\"))\n",
    "    activity = t.get(\"ActivityDate\")\n",
    "    is_overdue = False\n",
    "    if activity and not is_closed:\n",
    "        try:\n",
    "            is_overdue = date.fromisoformat(activity) < today\n",
    "        except ValueError:\n",
    "            is_overdue = False\n",
    "    if not is_closed:\n",
    "        open_cnt += 1\n",
    "    if is_overdue:\n",
    "        overdue_cnt += 1\n",
    "    tasks_payload.append(\n",
    "        {\n",
    "            \"Id\": t.get(\"Id\"),\n",
    "            \"Subject\": t.get(\"Subject\"),\n",
    "            \"Status\": t.get(\"Status\"),\n",
    "            \"Priority\": t.get(\"Priority\"),\n",
    "            \"ActivityDate\": activity,\n",
    "            \"IsClosed\": is_closed,\n",
    "            \"IsOverdue\": is_overdue,\n",
    "        }\n",
    "    )\n",
    "\n",
    "prompt_tasks = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a Salesforce productivity analyst. Given task records, surface concise, actionable insights.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Task data (JSON):\\n{tasks_json}\\n\\n\"\n",
    "            \"Counts: total={total_tasks}, open={open_tasks}, overdue={overdue_tasks}.\\n\"\n",
    "            \"Return 6-8 bullet points covering: themes/subjects, status mix, overdue items (mention subjects/priorities), \"\n",
    "            \"priority distribution, and quick risk/next-step notes. Keep bullets tight; no preamble or closing text.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain_tasks_v2 = prompt_tasks | llm | StrOutputParser()\n",
    "\n",
    "task_summary = chain_tasks_v2.invoke(\n",
    "    {\n",
    "        \"tasks_json\": json.dumps(tasks_payload[:60], default=str),\n",
    "        \"total_tasks\": len(tasks_payload),\n",
    "        \"open_tasks\": open_cnt,\n",
    "        \"overdue_tasks\": overdue_cnt,\n",
    "    }\n",
    ")\n",
    "\n",
    "print(task_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b491c26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Loaded 30 tasks | 18 open | 10 overdue\n",
      "\n",
      "================================================================================\n",
      "EXECUTING MEGA CHAIN: 10 LLM CALLS PIPED TOGETHER\n",
      "================================================================================\n",
      "Chain structure:\n",
      "prompt1 | llm | parser | transform\n",
      "  | prompt2 | llm | parser | transform\n",
      "  | prompt3 | llm | parser | transform\n",
      "  | prompt4 | llm | parser | transform\n",
      "  | prompt5 | llm | parser | transform\n",
      "  | prompt6 | llm | parser | transform\n",
      "  | prompt7 | llm | parser | transform\n",
      "  | prompt8 | llm | parser | transform\n",
      "  | prompt9 | llm | parser | transform\n",
      "  | prompt10 | llm | parser\n",
      "================================================================================\n",
      "\n",
      "Running chain... (this will take a minute as it calls the LLM 10 times)\n",
      "\n",
      "================================================================================\n",
      "FINAL OUTPUT: EXECUTIVE SUMMARY\n",
      "================================================================================\n",
      "\n",
      "\n",
      "**Situation:** Our IT strategy proactively targets technical debt reduction, system obsolescence mitigation, and resilience compliance to sustain critical operations. **Impact:** By enforcing strict modernization triggers and allocating dedicated resources, we minimize operational risk while exceeding 99.95% uptime for resilience-priority systems. **Path forward:** Continued adherence to quantified benchmarksâ€”including reallocating â‰¥20% of IT budgets to technical debtâ€”will uphold system viability amid evolving landscape pressures.\n",
      "\n",
      "âœ“ Successfully completed 10-step chained analysis!\n"
     ]
    }
   ],
   "source": [
    "# ONE MASSIVE CHAIN: prompt1|llm|parser|prompt2|llm|parser|prompt3|llm|parser...\n",
    "import json\n",
    "from datetime import date\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# Fetch task data\n",
    "task_rows = soql_query(\n",
    "    \"SELECT Id, Subject, Status, ActivityDate, IsClosed, Priority \"\n",
    "    \"FROM Task ORDER BY ActivityDate ASC NULLS LAST LIMIT 80\"\n",
    ")\n",
    "\n",
    "# Calculate metrics\n",
    "today = date.today()\n",
    "open_cnt = 0\n",
    "overdue_cnt = 0\n",
    "tasks_payload = []\n",
    "\n",
    "for t in task_rows:\n",
    "    is_closed = bool(t.get(\"IsClosed\"))\n",
    "    activity = t.get(\"ActivityDate\")\n",
    "    is_overdue = False\n",
    "    if activity and not is_closed:\n",
    "        try:\n",
    "            is_overdue = date.fromisoformat(activity) < today\n",
    "        except ValueError:\n",
    "            is_overdue = False\n",
    "    if not is_closed:\n",
    "        open_cnt += 1\n",
    "    if is_overdue:\n",
    "        overdue_cnt += 1\n",
    "    tasks_payload.append(\n",
    "        {\n",
    "            \"Id\": t.get(\"Id\"),\n",
    "            \"Subject\": t.get(\"Subject\"),\n",
    "            \"Status\": t.get(\"Status\"),\n",
    "            \"Priority\": t.get(\"Priority\"),\n",
    "            \"ActivityDate\": activity,\n",
    "            \"IsClosed\": is_closed,\n",
    "            \"IsOverdue\": is_overdue,\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(f\"ðŸ“Š Loaded {len(tasks_payload)} tasks | {open_cnt} open | {overdue_cnt} overdue\\n\")\n",
    "\n",
    "# =============================================================================\n",
    "# ONE GIANT CHAIN - All Steps Piped Together!\n",
    "# =============================================================================\n",
    "\n",
    "mega_chain = (\n",
    "    # STEP 1: Extract Themes\n",
    "    ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Extract task themes. Output only theme list.\"),\n",
    "        (\"human\", \"<tasks>{tasks_json}</tasks>\\nList 4-6 themes. Output ONLY bullet points.\")\n",
    "    ])\n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    "    \n",
    "    # Transform for Step 2\n",
    "    | RunnableLambda(lambda themes: {\"themes\": themes})\n",
    "    \n",
    "    # Transform for Step 2 (REMOVED - passing direct string)\n",
    "    # | RunnableLambda(lambda themes: {\"themes\": themes})\n",
    "    \n",
    "    # STEP 2: Analyze Priority Distribution  \n",
    "    | ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Analyze task priority patterns.\"),\n",
    "        (\"human\", \"<themes>{themes}</themes>\\nAnalyze priority distribution patterns. Output ONLY bullet points.\")\n",
    "    ])\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    \n",
    "    # Transform for Step 3\n",
    "    | RunnableLambda(lambda priorities: {\"priorities\": priorities})\n",
    "    \n",
    "    # STEP 3: Identify Overdue Patterns\n",
    "    | ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Identify overdue task patterns.\"),\n",
    "        (\"human\", \"<priorities>{priorities}</priorities>\\nIdentify overdue patterns and risks. Output ONLY bullet points.\")\n",
    "    ])\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    \n",
    "    # Transform for Step 4\n",
    "    | RunnableLambda(lambda overdue: {\"overdue_patterns\": overdue})\n",
    "    \n",
    "    # STEP 4: Synthesize Critical Problems\n",
    "    | ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Synthesize critical business problems.\"),\n",
    "        (\"human\", \"<overdue_patterns>{overdue_patterns}</overdue_patterns>\\nSynthesize 3-4 critical problems. Output ONLY bullet points.\")\n",
    "    ])\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    \n",
    "    # Transform for Step 5\n",
    "    | RunnableLambda(lambda problems: {\"problems\": problems})\n",
    "    \n",
    "    # STEP 5: Assess Business Impact\n",
    "    | ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Assess business impact of problems.\"),\n",
    "        (\"human\", \"<problems>{problems}</problems>\\nAssess business impact (revenue, compliance, efficiency). Output ONLY bullet points.\")\n",
    "    ])\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    \n",
    "    # Transform for Step 6\n",
    "    | RunnableLambda(lambda impacts: {\"impacts\": impacts})\n",
    "    \n",
    "    # STEP 6: Identify Root Causes\n",
    "    | ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Identify systemic root causes.\"),\n",
    "        (\"human\", \"<impacts>{impacts}</impacts>\\nIdentify 3-4 root causes (not symptoms). Output ONLY bullet points.\")\n",
    "    ])\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    \n",
    "    # Transform for Step 7\n",
    "    | RunnableLambda(lambda root_causes: {\"root_causes\": root_causes})\n",
    "    \n",
    "    # STEP 7: Brainstorm Solutions\n",
    "    | ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Brainstorm solutions.\"),\n",
    "        (\"human\", \"<root_causes>{root_causes}</root_causes>\\nBrainstorm 5-7 solutions. Output ONLY bullet points.\")\n",
    "    ])\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    \n",
    "    # Transform for Step 8\n",
    "    | RunnableLambda(lambda solutions: {\"solutions\": solutions})\n",
    "    \n",
    "    # STEP 8: Prioritize Solutions\n",
    "    | ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Prioritize solutions by impact/effort.\"),\n",
    "        (\"human\", \"<solutions>{solutions}</solutions>\\nRank top 4-5 by impact/effort ratio. Output ONLY numbered list.\")\n",
    "    ])\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    \n",
    "    # Transform for Step 9\n",
    "    | RunnableLambda(lambda prioritized: {\"prioritized_solutions\": prioritized})\n",
    "    \n",
    "    # STEP 9: Define Success Metrics\n",
    "    | ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Define measurable KPIs.\"),\n",
    "        (\"human\", \"<solutions>{prioritized_solutions}</solutions>\\nDefine 3-4 KPIs with target numbers. Output ONLY bullet points.\")\n",
    "    ])\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    \n",
    "    # Transform for Step 10\n",
    "    | RunnableLambda(lambda metrics: {\"metrics\": metrics})\n",
    "    \n",
    "    # STEP 10: Create Executive Summary\n",
    "    | ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Create executive summary.\"),\n",
    "        (\"human\", \"<metrics>{metrics}</metrics>\\nCreate 3-sentence executive summary: situation, impact, path forward. Output ONLY the summary.\")\n",
    "    ])\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# EXECUTE THE MEGA CHAIN - ONE INVOKE CALL!\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"EXECUTING MEGA CHAIN: 10 LLM CALLS PIPED TOGETHER\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Chain structure:\")\n",
    "print(\"prompt1 | llm | parser | transform\")\n",
    "print(\"  | prompt2 | llm | parser | transform\")\n",
    "print(\"  | prompt3 | llm | parser | transform\")\n",
    "print(\"  | prompt4 | llm | parser | transform\")\n",
    "print(\"  | prompt5 | llm | parser | transform\")\n",
    "print(\"  | prompt6 | llm | parser | transform\")\n",
    "print(\"  | prompt7 | llm | parser | transform\")\n",
    "print(\"  | prompt8 | llm | parser | transform\")\n",
    "print(\"  | prompt9 | llm | parser | transform\")\n",
    "print(\"  | prompt10 | llm | parser\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Initial input\n",
    "initial_input = {\n",
    "    \"tasks_json\": json.dumps(tasks_payload[:60], default=str)\n",
    "}\n",
    "\n",
    "# ONE INVOKE CALL - RUNS ALL 10 STEPS!\n",
    "print(\"Running chain... (this will take a minute as it calls the LLM 10 times)\\n\")\n",
    "executive_summary = mega_chain.invoke(initial_input)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FINAL OUTPUT: EXECUTIVE SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(executive_summary)\n",
    "print()\n",
    "print(\"âœ“ Successfully completed 10-step chained analysis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf5e085",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ACDevHub Python",
   "language": "python",
   "name": "acdevhub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
